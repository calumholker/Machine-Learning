{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "tensorflow",
   "display_name": "tensorflow",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2.4.0-rc0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v2 as tf\n",
    "tf.enable_v2_behavior()\n",
    "from tensorflow.python.framework.ops import disable_eager_execution\n",
    "disable_eager_execution()\n",
    "print(tf.__version__)\n",
    "import numpy as np\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train on 17462 samples, validate on 7484 samples\n",
      "Epoch 1/10\n",
      "17462/17462 [==============================] - 82s 5ms/sample - loss: 0.6498 - accuracy: 0.6063 - val_loss: 0.5800 - val_accuracy: 0.7008\n",
      "Epoch 2/10\n",
      "17462/17462 [==============================] - 76s 4ms/sample - loss: 0.5647 - accuracy: 0.7089 - val_loss: 0.5226 - val_accuracy: 0.7435\n",
      "Epoch 3/10\n",
      "17462/17462 [==============================] - 76s 4ms/sample - loss: 0.5100 - accuracy: 0.7525 - val_loss: 0.5198 - val_accuracy: 0.7451\n",
      "Epoch 4/10\n",
      "17462/17462 [==============================] - 73s 4ms/sample - loss: 0.4721 - accuracy: 0.7778 - val_loss: 0.4833 - val_accuracy: 0.7671\n",
      "Epoch 5/10\n",
      "17462/17462 [==============================] - 72s 4ms/sample - loss: 0.4479 - accuracy: 0.7936 - val_loss: 0.4662 - val_accuracy: 0.7813\n",
      "Epoch 6/10\n",
      "17462/17462 [==============================] - 69s 4ms/sample - loss: 0.4229 - accuracy: 0.8061 - val_loss: 0.4371 - val_accuracy: 0.7934\n",
      "Epoch 7/10\n",
      "17462/17462 [==============================] - 73s 4ms/sample - loss: 0.3954 - accuracy: 0.8212 - val_loss: 0.4397 - val_accuracy: 0.7978\n",
      "Epoch 8/10\n",
      "17462/17462 [==============================] - 69s 4ms/sample - loss: 0.3705 - accuracy: 0.8330 - val_loss: 0.4144 - val_accuracy: 0.8093\n",
      "Epoch 9/10\n",
      "17462/17462 [==============================] - 69s 4ms/sample - loss: 0.3478 - accuracy: 0.8482 - val_loss: 0.4099 - val_accuracy: 0.8173\n",
      "Epoch 10/10\n",
      "17462/17462 [==============================] - 73s 4ms/sample - loss: 0.3263 - accuracy: 0.8546 - val_loss: 0.4190 - val_accuracy: 0.8163\n",
      "Train on 17462 samples, validate on 7484 samples\n",
      "Epoch 1/10\n",
      "17462/17462 [==============================] - 83s 5ms/sample - loss: 0.6514 - accuracy: 0.6089 - val_loss: 0.5872 - val_accuracy: 0.6917\n",
      "Epoch 2/10\n",
      "17462/17462 [==============================] - 85s 5ms/sample - loss: 0.5532 - accuracy: 0.7221 - val_loss: 0.5467 - val_accuracy: 0.7237\n",
      "Epoch 3/10\n",
      "17462/17462 [==============================] - 85s 5ms/sample - loss: 0.4920 - accuracy: 0.7628 - val_loss: 0.5071 - val_accuracy: 0.7533\n",
      "Epoch 4/10\n",
      "17462/17462 [==============================] - 71s 4ms/sample - loss: 0.4552 - accuracy: 0.7862 - val_loss: 0.4433 - val_accuracy: 0.7960\n",
      "Epoch 5/10\n",
      "17462/17462 [==============================] - 72s 4ms/sample - loss: 0.4098 - accuracy: 0.8119 - val_loss: 0.4387 - val_accuracy: 0.7985\n",
      "Epoch 6/10\n",
      "17462/17462 [==============================] - 70s 4ms/sample - loss: 0.3736 - accuracy: 0.8351 - val_loss: 0.4104 - val_accuracy: 0.8123\n",
      "Epoch 7/10\n",
      "17462/17462 [==============================] - 74s 4ms/sample - loss: 0.3404 - accuracy: 0.8496 - val_loss: 0.4038 - val_accuracy: 0.8179\n",
      "Epoch 8/10\n",
      "17462/17462 [==============================] - 69s 4ms/sample - loss: 0.3095 - accuracy: 0.8666 - val_loss: 0.4132 - val_accuracy: 0.8167\n",
      "Epoch 9/10\n",
      "17462/17462 [==============================] - 69s 4ms/sample - loss: 0.2757 - accuracy: 0.8837 - val_loss: 0.4289 - val_accuracy: 0.8147\n",
      "Epoch 10/10\n",
      "17462/17462 [==============================] - 72s 4ms/sample - loss: 0.2466 - accuracy: 0.8944 - val_loss: 0.4360 - val_accuracy: 0.8151\n"
     ]
    }
   ],
   "source": [
    "pickle_in = open(\"X.pickle\",\"rb\")\n",
    "X = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"y.pickle\",\"rb\")\n",
    "y = pickle.load(pickle_in)\n",
    "\n",
    "X = np.array(X/255.0)\n",
    "y = np.array(y)\n",
    "\n",
    "dense_layers = [0,1]\n",
    "layer_sizes = [64]\n",
    "conv_layers = [3]\n",
    "\n",
    "for dense_layer in dense_layers:\n",
    "    for layer_size in layer_sizes:\n",
    "        for conv_layer in conv_layers:\n",
    "            NAME = \"{}-conv-{}-nodes-{}-dense-{}\".format(conv_layer, layer_size, dense_layer, int(time.time())) \n",
    "\n",
    "            tensorboard = TensorBoard(log_dir='logs/{}'.format(NAME))\n",
    "\n",
    "            model = Sequential()\n",
    "\n",
    "            model.add(Conv2D(layer_size, (3, 3), input_shape=X.shape[1:]))\n",
    "            model.add(Activation('relu'))\n",
    "            model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "            for l in range(conv_layer-1):\n",
    "                model.add(Conv2D(layer_size, (3, 3)))\n",
    "                model.add(Activation('relu'))\n",
    "                model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "            model.add(Flatten())\n",
    "\n",
    "            for l in range(dense_layer):\n",
    "                model.add(Dense(layer_size))\n",
    "                model.add(Activation('relu'))\n",
    "\n",
    "            model.add(Dense(1))\n",
    "            model.add(Activation('sigmoid'))\n",
    "\n",
    "            model.compile(loss='binary_crossentropy',\n",
    "                        optimizer='adam',\n",
    "                        metrics=['accuracy'])\n",
    "\n",
    "            model.fit(X, y, batch_size=32, epochs=10, validation_split=0.3, callbacks=[tensorboard]) # Note lots of other callback options see tensorflow website\n",
    "\n",
    "# For terminal\n",
    "# tensorboard --logdir='logs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}